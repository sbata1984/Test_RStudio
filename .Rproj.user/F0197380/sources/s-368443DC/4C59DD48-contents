library(timeDate)
library(tinytex)
library(urca)
library(xts)
library(sugrrants)
library(tidyselect)
library(tidyverse)
library(png)
library(rlang)
library(rmarkdown)
library(seasonal)
library(plyr)
library(GGally)
library(fpp3)
library(fpp2)
library(fpp)
library(feasts)
library(fma)
library(forcats)
library(fable)
library(expsmooth)
library(dbplyr)
library(dplyr)
library(tsoutliers)
library(ggpubr)
library(ggrepel)
library(ggsci)
library(ggsignif)
library(cowplot)
library(anytime)
library(astsa)
library(broom)
library(r4ds)
library(tidyverse)
library(openxlsx)
library(plotly)
library(zoo)
########Forecast and PRediction for MAster#############
#Generalised least squares------------------
##fitting procedure known as generalised least squares (GLS) can be used to provide better estimates of the standard error
#####ERTE Muster 
#Daten vorbereiten_______________________________________
y=na.omit(Kaffe_m)%>%   #remove NA
mutate(Month = seq.Date(as.Date("2016-10-01"),by="months",length.out = 45))

y=y%>%
filter(Bestellung > 1)
nrow(y)#43 row
ari
 
names(kl)[1] <- "Datum"#rename this column
as.Date(kl$Datum)
autoplot(y)+autolayer(,season_adjust,color="blue")
str(Kaffe_m)

x<-na.omit(Kaffe_m)
x$Letzte.Zeichen<-NULL

ts.kaff<-ts(x, start = c(10,2016),freq=12)
ts.plot(ts.kaff)
acf(ts.kaff,main="  ")#ACF told us about seasonality
pacf(ts.kaff)
mod3<-arima(x=ts.kaff,order=c(1,1,2))
fit.mod<-fitted(mod3)#fitted the model
plot(forecast(mod3))#use forecast funktion for plt the forecast
predict(fit.mod)
Box.test(ts.kaff,lag = log(length(ts.kaff)))
 p-value = 0.3354#for diff
 p-value = 0.0003039#without diff
 checkresiduals(mod3)
 summary(mod3)
####################
plot(diff(ts.kaff))
acf(diff(ts.kaff))#hier kann man sehen, dass wir eine Trend ahben aber keine Klare Saisonalität
pacf(diff(ts.kaff))
aus ersten bild kann man sehen,dass die TS.Kaffe eine random.Wolk Serie mit ein Starken sinkende Trend und Glathe Ablauf.
bestimme die Verteilung
layout(1:2)
par(mar = rep(2, 4))
hist(Kaffe_m$Bestellung,nclass=20,xlab="", main="",col="brown")
hist(Kaffe_Bestellung.tr,nclass=20,xlab="", main="",col="blue")#neue Verteilung nach stabilasation von Varianz
#Datenverteilung
ggpairs(data= Kaffe_m, # data.frame with variables
       # columns= c(2), # columns to plot, default to all.
        title="tips data")# title of the plot
           #mapping = ggplot2::aes(colour=Sex),
                     
        #colour = "Sex") # aesthetics, ggplot2 style
_____________________________________________________________________________________________
#--------------------trend Schätzung----Trend Glätung-----------------------
Kaffe_Bestellung.tr = sqrt(Kaffe_m$Bestellung +3/8)
Ka_Bestellung=Kaffe_m$Bestellung
time.pts=c(1:length(Ka_Bestellung))#Vector Die Länge der Zeitpunkt der unserer TS bestimmen
time.pts=c(time.pts-min(time.pts))/max(time.pts)#Vector von Normalisierte Werte
##Local Polynomial Trend Estimation
local.fit=loess(Ka_Bestellung~ time.pts)
vol.fit.local=fitted(local.fit)#fitted the polyno
##Generalized additive models with integrated smoothness estimation
##Splines Trend Estimation
library(mgcv)
gam.fit=gam(Ka_Bestellung~s(time.pts))
vol.gam.fit=fitted(gam.fit)
Kaffe_m<-  mutate(Kaffe_m, Datum = seq.Date(as.Date("2016-10-01"),length.out = 46, by="months"))#creat a date Columne
Kaffe_m$`Letzte Zeichen`<-NULL
Kaffe_m$Bestellung<- ifelse(is.na(Kaffe_m$Bestellung),as.numeric(0),Kaffe_m$Bestellung)#NA value with 0 switchen
Kaffe_m$Bestellung=as.numeric(Kaffe_m$Bestellung)
##is there a trend
attach(Kaffe_m)
plot( Kaffe_m$Datum,Bestellung,type = "l")
lines( Kaffe_m$Datum,vol.fit.local,lwd="2",col="brown")#Träge reagiert langsam auf änderung
lines( Kaffe_m$Datum,vol.gam.fit,lwd="2",col="red")#Spline hat starke wendepunkte
vol.fit.local#
vol.gam.fit#Spline
summary(gam.fit)#ist statistical Signifikant denn Alpha ist sehr klein
Formula:
Ka_Bestellung ~ s(time.pts)

Parametric coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)   21.391      1.713   12.49 9.73e-15 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Approximate significance of smooth terms:
              edf Ref.df     F p-value    
s(time.pts) 8.532  8.938 7.125 1.4e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-sq.(adj) =  0.575   Deviance explained = 65.6% #66% der werte  wurde bei den Trend fest gestellt
GCV = 170.21  Scale est. = 134.94    n = 46

Kaffe_m<-mutate(Kaffe_m,  week=as.factor(weekdays(Kaffe_m$Datum)))#creat a colume with weekdays
gam.fit.sea=gam(Bestellung ~ s(time.pts)+month)

___________________________________________________________________________________________


Seas<-cycle(temp)#extracted the seasonality
Time<-time(temp)#time  data
temp.lm<-lm(temp ~ 0+Time+factor(Seas))#fitted a Linear model A zero is used within the formula to ensure that the model does not have an intercept
coef(temp.lm)
ts.plot(temp)  
new.t <- seq(2006, len = 2 * 12, by = 1/12)
alpha <- coef(temp.lm)[1]
beta <- rep(coef(temp.lm)[2:13], 2)
(alpha * new.t + beta)[1:6]#theformel for 2 Year
factor(Seas)1 factor(Seas)2 factor(Seas)3 factor(Seas)4 
0.5241458     0.5348681     0.5143403     0.5135625 
#or as DF-----------------
Alternatively, the predict function can be used to make forecasts provided
the new data are correctly labelled within a data.frame:
new.dat <- data.frame(Time = new.t, Seas = rep(1:12, 2))
 predict(temp.lm, new.dat)[1:24]#predicet per month
 #Hier neue Column mit order und mutate
 bike_sales_monthly <- bike_sales %>%
    mutate(month = month(order.date, label = TRUE),
           year  = year(order.date)) %>%
    group_by(year, month) %>%
    summarise(total.qty = sum(quantity)) 
 ##
 monthly_qty_by_cat2 <- bike_sales %>%
    mutate(order.month = as_date(as.yearmon(order.date))) %>%
    group_by(category.secondary, order.month) %>%
    summarise(total.qty = sum(quantity))

 